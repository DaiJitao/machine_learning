"""
ç–«æƒ…æœŸé—´ç½‘æ°‘æƒ…ç»ªè¯†åˆ«
"""

import numpy as np
import jieba_fast as jieba
import pandas as pd
import re
import json


def load_data(file):
    data_df = pd.read_csv(file, encoding='utf-8')
    content = data_df['å¾®åšä¸­æ–‡å†…å®¹']
    label = data_df['æƒ…æ„Ÿå€¾å‘']
    content_cleaned = content.apply(clean_text)
    count = 0
    new_df = pd.DataFrame({"åŽŸæ–‡": content, "æ¸…æ´—": content_cleaned})
    new_df.to_csv(r"F:\NLP_learnings\data\dataFountain\train_ dataset\clean_test.csv", encoding='utf-8', index=False)


def cut_words(text):
    jieba.cut


def clean_text(text):
    text = str(text)
    # åŽ»æŽ‰urlåœ°å€
    text = re.sub('''http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\(\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+''', '', text)
    # åŽ»æŽ‰@æŸæŸæŸ
    text = re.sub('''@.+@.+([\n]|[\t])''', '', text)
    # text = re.sub("(ã€ï¼Œ)|@|//@|ï½ž|>{1,}|\(\)", "ï¼Œ", text)
    text = re.sub("[(ã€‚ï¼Œ)(ï¼ï¼Œ)(ï¼Ÿï¼Œ)(ã€ï¼Œ)@(//@)ï½ž>\(\)]{1,}", "ï¼Œ", text)
    # å¤šä¸ªé—®å·å˜ä¸ºä¸€ä¸ªé—®å·
    text = re.sub(r"[ã€‚ï¼Ÿ\?]{2,}", "ï¼Ÿ", text)
    text = re.sub(r"[ï¼!]{2,}", "ï¼", text)
    # åŽ»æŽ‰#æŸæŸæŸ# å’Œå•ä¸ªå­—æ¯å•ä¸ªæ•°å­—
    text = re.sub("è½¬å‘å¾®åš|#.{1,6}#|å±•å¼€å…¨æ–‡|([a-zA-Z]|[0-9])", "", text)
    # ï¼Ÿ? -> ?
    text = re.sub(r"(\?ï¼Ÿ)|(ï¼Ÿ\?)", "ï¼Ÿ", text)
    text = re.sub(r"â€”{2,}|-{2,}", "â€”", text)
    text = re.sub(r"â€¦{1,}|\.{4,}", "â€¦", text)
    r = u'[/ã€ã€‘â—â– ï¿½â†’ï¼Žãƒ»ðŸ‡¨ðŸ‡³ï¼™ï¼˜ï¼—ï¼–ï¼•ï¼”ï¼“ï¼’ï¼‘ï¼ï¼ï¼…ï¼»ï¼½Ã—\[\]^_`{|}~(:Ð·ã€âˆ )]'
    text = re.sub(r, "ï¼Œ", text)
    # åŽ»æŽ‰éžä¸­æ–‡
    not_chinese = r'[^\u4e00-\u9fa5ï¼Œ{}ã€ã€‘ï¼ˆï¼‰ã€‚ï¼šï¼›â€œâ€˜â€â€¦ã€Šã€‹ã€ï¼ï¼Ÿâ€”â€”]'
    text = re.sub(not_chinese, " ", text)
    # å¤šä¸ªç©ºæ ¼å˜ä¸º1ä¸ª
    text = re.sub(r"\s{1,}", " ", text)
    text = re.sub(r"[(\sï¼Œ)(\s,),ï¼Œ(ï¼ˆï¼‰)(ï¼šï¼Œ)(ï¼š ï¼š)]{1,}", "ï¼Œ", text).strip()
    return text


if __name__ == '__main__':
    # file_train_csv = r"F:\NLP_learnings\data\dataFountain\train_ dataset\nCoV_100k_train.labled.csv"
    # load_data(file=file_train_csv)

    file = r"F:\pycharm_workspce\dai_github\ml_test1\machine_learning\demo\data_fountain\data\hotworddata2.txt"
    with open(file=file, mode='r', encoding='utf-8') as fp:
        for line in fp.readlines():
            d = json.loads(line)['content']
            print(d)
            print("-->")
            print(clean_text(d))
            print("\n\n\n")

